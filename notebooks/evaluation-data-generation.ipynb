{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641207ec-4952-4521-a8df-1482aa9bd01d",
   "metadata": {},
   "source": [
    "## ground-truth-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "789cbaea-545c-43be-9d90-861498c5fa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading document chunks from: /workspaces/knowledge-base-assistant/data/data.jsonl\n",
      "Successfully loaded 217 document chunks (with 'embedding' field removed).\n",
      "\n",
      "Documents keys loaded:\n",
      "['document_metadata', 'chunk_id', 'section_title', 'chunk_type', 'page_number', 'content', 'id', 'title', 'url', 'text']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..')) \n",
    "data_path = os.path.join(PROJECT_ROOT, 'data', 'data.jsonl')\n",
    "output_path = os.path.join(PROJECT_ROOT, 'data', 'data.csv')\n",
    "\n",
    "print(f\"Loading document chunks from: {data_path}\")\n",
    "\n",
    "documents = []\n",
    "with open(data_path, 'rt', encoding='utf-8') as f_in:\n",
    "    for line in f_in:\n",
    "        doc = json.loads(line)\n",
    "        doc.pop('embedding', None)\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Successfully loaded {len(documents)} document chunks (with 'embedding' field removed).\")\n",
    "\n",
    "# Checking first document to confirm\n",
    "if documents:\n",
    "    print(\"\\nDocuments keys loaded:\")\n",
    "    print(list(documents[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd30fc57-cb7b-489d-9f05-406b3fc36da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved 217 records to: /workspaces/knowledge-base-assistant/data/data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(documents)\n",
    "metadata_df = pd.json_normalize(df['document_metadata'])\n",
    "metadata_df.rename(columns={'title': 'document_title', 'url': 'document_url'}, inplace=True)\n",
    "df = df.drop(columns=['document_metadata']).join(metadata_df)\n",
    "\n",
    "if 'embedding' in df.columns:\n",
    "    df = df.drop(columns=['embedding'])\n",
    "    print(\"'embedding' column removed.\")\n",
    "\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"\\nSuccessfully saved {len(df)} records to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1528b3-b34c-43bd-8743-77f98b29a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06749aeb-2fd8-4523-9ffe-8d76b489b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3f9f88-1e97-4807-9293-cb3a00398dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashes = defaultdict(list)\n",
    "\n",
    "# for doc in documents:\n",
    "#     doc_id = doc['id']\n",
    "#     hashes[doc_id].append(doc)\n",
    "\n",
    "# len(hashes), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d9e161-a897-4a37-9b82-765e03475714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238a631f-ea3a-4662-8281-70e77c0f369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an AI assistant tasked with creating a high-quality ground-truth dataset for evaluating a Retrieval-Augmented Generation (RAG) system.\n",
    "Your role is to act as an inquisitive researcher or engineer and generate **5 distinct, realistic, and high-quality questions** that can be **completely answered** using only the information in the provided CONTEXT.\n",
    "\n",
    "### RULES:\n",
    "1. **Exactly Five Questions**: Produce precisely 5 questions, no more, no less.\n",
    "2. **Grounded in Context**: Each question must be answerable *exclusively* from the provided CONTEXT. Do not introduce outside knowledge.\n",
    "3. **Realistic User Queries**: Formulate questions as if they were asked by a real person seeking information. Avoid exam-style or trivial “fill-in-the-blank” questions.\n",
    "4. **Clarity and Precision**: Questions should be well-structured, specific, and self-contained. Avoid ambiguity and overly short phrasing.\n",
    "5. **No Copy-Paste**: Do not copy sentences verbatim from the CONTEXT. Always rephrase naturally, ensuring the question sounds conversational.\n",
    "6. **Variety of Question Types**: Mix styles and intents (e.g., definitions, comparisons, processes, causes/effects, implications, factual lookups). At least one “how/why” style question is required.\n",
    "7. **Balanced Scope**: Avoid questions that are either too broad (\"Explain everything about…\") or too narrow (\"What is the third word in…\"). Each question should target a meaningful, self-contained piece of information.\n",
    "\n",
    "### CONTEXT:\n",
    "---\n",
    "Source Document: {title}\n",
    "Section: {section_title} (Page {page_number})\n",
    "Content: {content}\n",
    "---\n",
    "\n",
    "### OUTPUT FORMAT:\n",
    "Return the result as a single valid parsable JSON (without markdown/code block formatting), exactly in this structure:\n",
    "{{\"questions\": [\"question1\", \"question2\", \"question3\", \"question4\", \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96164365-ba9a-465f-b695-9e9347a8a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(**documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0704ddc0-3ec5-4313-8414-9af245ead40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9edcd3dd-099e-44c2-9815-10b686a3d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17efbb3d-beff-493c-a6b2-af0d412e37ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['What is the main factor contributing to safety incidents in high-risk industries according to the research mentioned?',\n",
       "  'Can you explain what Crew Resource Management (CRM) refers to in the context of non-technical skills?',\n",
       "  'What is the title of the program developed to enhance situational awareness competencies in employees?',\n",
       "  'How does the Permanent Attention program aim to improve situational awareness among front-line employees?',\n",
       "  'Which fields did the program draw best practices from to achieve improvements in non-technical skills?']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aeacbe9-4094-4112-b245-6c1885f88136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "def safe_generate_questions(doc, max_retries=MAX_RETRIES):\n",
    "    \"\"\"\n",
    "    Generate questions and ensure valid JSON output.\n",
    "    Retries up to `max_retries` times if JSON decoding fails.\n",
    "    \"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        questions_raw = generate_questions(doc)\n",
    "\n",
    "        try:\n",
    "            questions = json.loads(questions_raw)\n",
    "            # Ensure expected structure\n",
    "            if isinstance(questions, dict) and \"questions\" in questions:\n",
    "                return questions\n",
    "            else:\n",
    "                raise ValueError(\"Invalid JSON structure, missing 'questions' key\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Attempt {attempt}/{max_retries}] JSON parsing failed: {e}\")\n",
    "            \n",
    "            # Retry by asking LLM to strictly fix the format\n",
    "            fix_prompt = f\"\"\"\n",
    "            The following text was supposed to be valid JSON but is malformed:\n",
    "\n",
    "            {questions_raw}\n",
    "\n",
    "            Please return ONLY a valid JSON object in the form:\n",
    "            {{\"questions\": [\"question1\", \"question2\", \"question3\", \"question4\", \"question5\"]}}\n",
    "            \"\"\"\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": fix_prompt}]\n",
    "            )\n",
    "            questions_raw = response.choices[0].message.content\n",
    "\n",
    "            # Wait a bit between retries\n",
    "            time.sleep(1)\n",
    "\n",
    "    # If still failing after retries, log and skip\n",
    "    print(f\"❌ Failed to get valid JSON after {max_retries} attempts for doc {doc['id']}\")\n",
    "    return {\"questions\": []}  # fallback so pipeline continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbb3e573-fdb3-40a5-80ea-c6c3ff13b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9ccf618-9d02-43ea-b549-4f1b82c346ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53778b6c-cf86-477f-b42f-788c48f1d451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38898fd9b54458e940e9dc8708db8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 1/3] JSON parsing failed: Expecting ',' delimiter: line 1 column 488 (char 487)\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents): \n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions = safe_generate_questions(doc)\n",
    "    results[doc_id] = questions['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0cb7957-e350-4c17-a725-9140a50a5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "# import time\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# MAX_RETRIES = 3\n",
    "\n",
    "# def auto_fix_json(bad_json: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Attempt to fix JSON formatting issues without calling LLM again.\n",
    "#     - Removes markdown/code fences\n",
    "#     - Strips extra text before/after JSON\n",
    "#     - Fixes trailing commas\n",
    "#     \"\"\"\n",
    "#     # Remove code fences (```json ... ```)\n",
    "#     cleaned = re.sub(r\"^```(?:json)?|```$\", \"\", bad_json.strip(), flags=re.MULTILINE).strip()\n",
    "\n",
    "#     # Extract the first {...} block\n",
    "#     match = re.search(r\"\\{.*\\}\", cleaned, re.DOTALL)\n",
    "#     if match:\n",
    "#         cleaned = match.group(0)\n",
    "\n",
    "#     # Fix trailing commas before ] or }\n",
    "#     cleaned = re.sub(r\",\\s*([\\]}])\", r\"\\1\", cleaned)\n",
    "\n",
    "#     return cleaned\n",
    "\n",
    "\n",
    "# def safe_generate_questions(doc, max_retries=MAX_RETRIES):\n",
    "#     \"\"\"\n",
    "#     Generate questions and ensure valid JSON output.\n",
    "#     Retries with LLM reformatting if JSON decoding fails,\n",
    "#     and finally tries local auto-fix before giving up.\n",
    "#     \"\"\"\n",
    "#     questions_raw = None\n",
    "#     for attempt in range(1, max_retries + 1):\n",
    "#         questions_raw = generate_questions(doc)\n",
    "\n",
    "#         try:\n",
    "#             questions = json.loads(questions_raw)\n",
    "#             if isinstance(questions, dict) and \"questions\" in questions:\n",
    "#                 return questions\n",
    "#             else:\n",
    "#                 raise ValueError(\"Invalid JSON structure, missing 'questions' key\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"[Attempt {attempt}/{max_retries}] JSON parsing failed: {e}\")\n",
    "\n",
    "#             # Retry with LLM fix\n",
    "#             fix_prompt = f\"\"\"\n",
    "#             The following text was supposed to be valid JSON but is malformed:\n",
    "\n",
    "#             {questions_raw}\n",
    "\n",
    "#             Please return ONLY a valid JSON object in the form:\n",
    "#             {{\"questions\": [\"question1\", \"question2\", \"question3\", \"question4\", \"question5\"]}}\n",
    "#             \"\"\"\n",
    "#             response = client.chat.completions.create(\n",
    "#                 model=\"gpt-4o-mini\",\n",
    "#                 messages=[{\"role\": \"user\", \"content\": fix_prompt}]\n",
    "#             )\n",
    "#             questions_raw = response.choices[0].message.content\n",
    "\n",
    "#             time.sleep(1)\n",
    "\n",
    "#     # Final attempt: local auto-fix\n",
    "#     try:\n",
    "#         fixed = auto_fix_json(questions_raw)\n",
    "#         questions = json.loads(fixed)\n",
    "#         if isinstance(questions, dict) and \"questions\" in questions:\n",
    "#             print(f\"✅ Auto-fixed JSON for doc {doc['id']}\")\n",
    "#             return questions\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Auto-fix failed for doc {doc['id']}: {e}\")\n",
    "\n",
    "#     # If still bad, return empty structure\n",
    "#     return {\"questions\": []}\n",
    "\n",
    "\n",
    "# results = {}\n",
    "\n",
    "# for doc in tqdm(documents): \n",
    "#     doc_id = doc['id']\n",
    "#     if doc_id in results:\n",
    "#         continue\n",
    "\n",
    "#     questions = safe_generate_questions(doc)\n",
    "#     results[doc_id] = questions['questions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b8d7b2d-eb51-4496-a3c9-ef0f6e6fcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b432d2-168f-4786-aa99-424a1bb70c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        final_results.append((doc_id, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c7d5436-61b4-45b8-9653-7ab1c1748088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1001',\n",
       " 'What role do non-technical skills play in safety incidents in high-risk industries?')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0f707-3da9-4ff9-b71e-dbbc7a3943f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "210bdf41-3d6c-4abb-96c1-3fb2c893f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(final_results, columns=['id', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2095d4ff-3c14-439e-8d2d-4b8d07153197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('../data/ground-truth-retrieval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd43d38-08e8-420a-9a57-5e32b81b9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,question\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1001,What role do non-technical skills play in safety incidents in high-risk industries?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1001,Can you explain what the Permanent Attention program aims to achieve?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1001,How does the Permanent Attention program improve situational awareness competencies?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1001,What are the key components that the Permanent Attention program is based on?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1001,Why is situational awareness considered the most influential non-technical skill in the context of this research?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1002,What is the main focus of the paper discussed in the document?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1002,Which two key competencies are improved through the Permanent Attention program according to the abstract?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1002,Can you provide examples of organizations that implemented the program described in the paper?\n",
      "a-disruptive-approach-to-crm-and-situational-awareness-competenc_PAGE1002,How does the Permanent Attention program contribute to the retention of non-technical skills?\n"
     ]
    }
   ],
   "source": [
    "!head ../data/ground-truth-retrieval.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
